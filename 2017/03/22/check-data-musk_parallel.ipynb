{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %matplotlib notebook\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %reload_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "\n",
    "# def read_gas_array_data(dir_path):\n",
    "#     Xall = []\n",
    "#     Yall = []\n",
    "#     for i in xrange(1, 10):\n",
    "#         Xb, Yb = load_svmlight_file(dir_path + \"batch%d.dat\" % i)\n",
    "#         Xall.append(np.array(Xb.todense()))\n",
    "#         Yall.append(np.array(Yb))\n",
    "#     return np.concatenate(tuple(Xall)), np.concatenate(tuple(Yall))\n",
    "\n",
    "# Xall, Yall = read_gas_array_data(\"uci-data/Gas_Sensor_Array_Drift_Dataset_Data_Set/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# pd.DataFrame(Yall).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.hist(Yall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print Xall.shape, Yall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sm_mnlr = sm.MNLogit(Yall, sm.add_constant(Xall, prepend=False))\n",
    "# sm_mnlr_fit = sm_mnlr.fit(method=\"bfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_musk_data(file_path):\n",
    "    with open(file_path, 'r') as fin:\n",
    "        dat_all = []\n",
    "        for line in fin:\n",
    "            line = line.strip()[:-1].split(\",\")[2:]\n",
    "            dat_all.append(line)\n",
    "    dat_all = np.array(dat_all, dtype=np.float)\n",
    "    return dat_all[:, :-1], dat_all[:, -1]\n",
    "\n",
    "            \n",
    "Xm, Ym = read_musk_data(\"uci-data/musk_clean2.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6598, 166)\n",
      "(6598,)\n"
     ]
    }
   ],
   "source": [
    "print Xm.shape\n",
    "print Ym.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n, p = Xm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.154138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.361108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  6598.000000\n",
       "mean      0.154138\n",
       "std       0.361108\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       0.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Ym).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(Xm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.109768\n",
      "         Iterations 12\n"
     ]
    }
   ],
   "source": [
    "sm_lr = sm.Logit(Ym, sm.add_constant(scaler.transform(Xm), prepend=False))\n",
    "sm_lr_fit = sm_lr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.38115146e+00  -3.50590412e-02  -1.82661806e-01 ...,   8.50703782e-02\n",
      "   -8.34996610e-02   9.42777144e-02]\n",
      " [ -3.50590412e-02   2.84149520e-01  -6.77511087e-02 ...,  -6.85519595e-04\n",
      "    1.03233680e-02  -2.08633977e-02]\n",
      " [ -1.82661806e-01  -6.77511087e-02   2.37082472e+00 ...,   4.92605324e-02\n",
      "    3.06908919e-02   5.12668999e-02]\n",
      " ..., \n",
      " [  8.50703782e-02  -6.85519595e-04   4.92605324e-02 ...,   4.36333129e-01\n",
      "   -5.40338036e-02   4.57211553e-02]\n",
      " [ -8.34996610e-02   1.03233680e-02   3.06908919e-02 ...,  -5.40338036e-02\n",
      "    1.09863270e-01  -5.86971805e-03]\n",
      " [  9.42777144e-02  -2.08633977e-02   5.12668999e-02 ...,   4.57211553e-02\n",
      "   -5.86971805e-03   6.02271206e-02]]\n"
     ]
    }
   ],
   "source": [
    "print sm_lr_fit.cov_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fad27a8ea90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.imshow(sm_lr_fit.cov_params(), cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fad279b0dd0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(sm_lr_fit.cov_params().diagonal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# NBS = 15000\n",
    "\n",
    "# w_bs = []\n",
    "\n",
    "# for _ in xrange(NBS):\n",
    "#     ind_bs = np.random.choice(n, size=n, replace=True)\n",
    "#     bs_lr = sm.Logit(Ym[ind_bs], sm.add_constant(scaler.transform(Xm[ind_bs, :]), prepend=False))\n",
    "#     bs_lr_fit = bs_lr.fit(disp=False)\n",
    "#     w_bs.append(bs_lr_fit.params.ravel().tolist())\n",
    "    \n",
    "\n",
    "# w_bs = np.array(w_bs)\n",
    "\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "# pickle.dump(w_bs, open(\"PICKLE_uci_musk_BS\", 'wb'))\n",
    "\n",
    "\n",
    "w_bs = pickle.load(open(\"/u/lty/scratch/data/PICKLE_uci_musk_BS\", 'rb'))\n",
    "\n",
    "\n",
    "cov_bs = np.cov(w_bs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fad279d0310>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(sm_lr_fit.cov_params().diagonal(), 'b', label=\"inv Fisher\")\n",
    "plt.plot(cov_bs.diagonal(), 'r', label=\"bootstrap\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import division\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "def sgd_avg_infer(X_, Y_, lr, \n",
    "                  size_batch, \n",
    "                  burn_in, n_avg, n_skip, n_sample):\n",
    "    lr = float(lr)\n",
    "    \n",
    "    n, p = X_.shape\n",
    "    \n",
    "    print n, p\n",
    "\n",
    "    sm_lr = sm.Logit(Y_, X_)\n",
    "    sm_lr_fit = sm_lr.fit(disp=False)\n",
    "    \n",
    "    \n",
    "    X = tf.placeholder(tf.float64, [None, p])\n",
    "    \n",
    "    Y = tf.placeholder(tf.float64, [None, 1])\n",
    "    \n",
    "    w = tf.Variable(initial_value=sm_lr_fit.params.reshape((-1, 1)), dtype=tf.float64)\n",
    "\n",
    "    print(w)\n",
    "    \n",
    "    \n",
    "    log_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.matmul(X, w), labels=Y))\n",
    "    \n",
    "    opt = tf.train.GradientDescentOptimizer(lr).minimize(log_loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    \n",
    "    \n",
    "    n_iter = burn_in + (n_avg + n_skip) * n_sample + 3\n",
    "    \n",
    "    \n",
    "    w_avg_samples = []\n",
    "    \n",
    "    w_all = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for i_ in xrange(n_iter):\n",
    "            ind_batch = np.random.choice(n, size=size_batch, replace=True)\n",
    "            \n",
    "            Xb = X_[ind_batch, :].reshape((-1, p))\n",
    "            Yb = Y_[ind_batch].reshape((-1, 1))\n",
    "            \n",
    "            sess.run([opt], feed_dict={X: Xb, Y: Yb})\n",
    "            \n",
    "            if i_ >= burn_in:\n",
    "                if (i_ - burn_in) % (n_avg + n_skip) < n_avg:\n",
    "                    wb = w.eval(session=sess).ravel().tolist()\n",
    "                    w_avg_samples.append(wb)\n",
    "                elif (i_ - burn_in) % (n_avg + n_skip) == n_avg:\n",
    "                    w_avg_samples = np.array(w_avg_samples)\n",
    "                    w_avg = np.mean(w_avg_samples, axis=0)\n",
    "                    w_all.append(w_avg.ravel().tolist())\n",
    "                    w_avg_samples = []\n",
    "    \n",
    "    return np.array(w_all)  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6598 167\n",
      "6598 167\n",
      "6598 167\n",
      "Tensor(\"Variable/read:0\", shape=(167, 1), dtype=float64)\n",
      "Tensor(\"Variable/read:0\", shape=(167, 1), dtype=float64)\n",
      "Tensor(\"Variable/read:0\", shape=(167, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "burn_in = 20\n",
    "\n",
    "# n_avg = 5000\n",
    "# n_skip = 100\n",
    "# n_sample = 5000\n",
    "\n",
    "\n",
    "n_avg = 2000\n",
    "n_skip = 70\n",
    "\n",
    "n_sample = 1000\n",
    "\n",
    "lr = .05\n",
    "\n",
    "size_batch = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mpool = multiprocessing.Pool(processes=8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mpool_args = []\n",
    "\n",
    "\n",
    "#########\n",
    "\n",
    "for n_avg in [7000, 14000, 21000, 28000, 35000]:\n",
    "    for lr in [1, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.002, 0.001]:\n",
    "        for size_batch in [2, 4, 8, 16]:\n",
    "\n",
    "#             n_avg = 2000\n",
    "            n_skip = 1000\n",
    "\n",
    "            n_sample = 5000\n",
    "\n",
    "#             lr = .05\n",
    "\n",
    "#             size_batch = 10\n",
    "\n",
    "            mpool_args.append((sm.add_constant(Xm, prepend=False), Ym, lr, size_batch, burn_in, n_avg, n_skip, n_sample))\n",
    "\n",
    "\n",
    "#########\n",
    "\n",
    "\n",
    "    \n",
    "# w_sgd_avg = sgd_avg_infer(sm.add_constant(Xm, prepend=False), Ym, lr, size_batch, burn_in, n_avg, n_skip, n_sample)\n",
    "    \n",
    "\n",
    "results = [mpool.apply_async(sgd_avg_infer, mpool_arg) for mpool_arg in mpool_args]\n",
    "    \n",
    "    \n",
    "mpool.close()\n",
    "mpool.join()\n",
    "\n",
    "\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "# pickle.dump(sim_res, open(\"logistic-large_2017_03_01\", 'wb'))\n",
    "\n",
    "results_ = [r.get() for r in results]\n",
    "\n",
    "pickle.dump({\"mpool_args\": mpool_args, \"results\": results_}, open(\"/u/lty/scratch/results/check-data-musk_parallel_03_21_17_21\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w_sgd_avg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9d61507c86df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#figsize=(12,8))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mline_sgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_sgd_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SGD Inference'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mline_fisher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm_lr_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Fisher'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w_sgd_avg' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# plt.figure()#figsize=(12,8))\n",
    "\n",
    "# line_sgd, = plt.plot(np.mean(w_sgd_avg, axis=0), label='SGD Inference')\n",
    "# line_fisher, = plt.plot(sm_lr_fit.params, label = 'Fisher')\n",
    "\n",
    "\n",
    "# plt.legend(handles=[line_sgd, line_fisher])\n",
    "\n",
    "# plt.title('Optimization output')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# cov_estimate = np.cov(w_sgd_avg.T) * size_batch / n * n_avg \n",
    "\n",
    "# from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "\n",
    "\n",
    "# # cov_estimate2 = MinCovDet().fit(w_sgd_avg) \n",
    "# # cov_estimate2 = size_batch / n * n_avg * cov_estimate2.covariance_\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# #plt.figure(figsize=(12,8))\n",
    "\n",
    "\n",
    "# line_sgd, = plt.plot(cov_estimate.diagonal(), 'r', label='SGD')\n",
    "\n",
    "# #line_fisher, = plt.plot(sm_lr_fit.cov_params().diagonal(), label = 'Fisher')\n",
    "\n",
    "# line_bs, = plt.plot(np.cov(w_bs.T).diagonal(), 'b', label=\"bootstrap\")\n",
    "\n",
    "# # plt.plot(sm_lr_fit.cov_params().diagonal(), 'b', label=\"inverse Fisher\")\n",
    "\n",
    "\n",
    "# plt.legend()#handles=[line_sgd, line_fisher, line_bs])\n",
    "\n",
    "# #plt.title('Diagonal')\n",
    "\n",
    "# # plt.ylim((0, 0.4))\n",
    "\n",
    "# plt.legend(prop={'size': 23})\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # plt.savefig(\"logistic-11d-rho-0_6--diag.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
